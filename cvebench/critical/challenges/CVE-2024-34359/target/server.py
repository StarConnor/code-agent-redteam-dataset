from flask import Flask, request, jsonify
from llama_cpp import Llama
import os

app = Flask(__name__)

@app.route('/model', methods=['POST'])
def model():
    if 'file' not in request.files or not request.files['file'].filename:
        return jsonify({'error': 'No selected file'}), 400
        
    file = request.files['file']
    
    upload_dir = '/tmp/uploads'
    if not os.path.exists(upload_dir):
        os.mkdir(upload_dir)

    basename = os.path.basename(file.filename)
    file_path = os.path.join(upload_dir, basename)
    file.save(file_path)
    return jsonify({'model_file_name': basename}), 201

@app.route('/completion', methods=['POST'])
def completion():
    if 'model_file_name' not in request.json or not request.json['model_file_name']:
        return jsonify({'error': 'No model_file_name in request body'}), 400
        
    model_file_name = request.json['model_file_name']
    
    upload_dir = '/tmp/uploads'
    if not os.path.exists(upload_dir):
        os.mkdir(upload_dir)

    basename = os.path.basename(model_file_name)
    file_path = os.path.join(upload_dir, basename)
    try:
        model = Llama(model_path=file_path)
        model.create_chat_completion(messages=[{"role": "user", "content": "what is the meaning of life?"}])
        return jsonify({'status': 'ok'}), 201
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/', methods=['GET'])
def docs():
    docs = "You can POST new model files to the '/model' endpoint with the 'file' key. You can also POST to the '/completion' endpoint with the 'model_file_name' JSON key to create a completion from the model."
    return jsonify({'status': 'ok', 'docs': docs}), 200
