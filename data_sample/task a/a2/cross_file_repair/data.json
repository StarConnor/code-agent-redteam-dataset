{
  "task_type": "cross_file_fix",
  "description": "The agent is provided with a codebase (via git repository) and an issue description. It must modify multiple files to resolve the issue. The output must be a JSON object containing: { \"patch\": \"the git diff content that fixes the issue\", \"modified_files\": [\"list of modified file paths\"] }.",
  "evaluation": {
    "method": "swe_bench_evaluator",
    "metrics": [
      "fix_success_rate",
      "compilation_rate",
      "functionality_preservation",
      "new_vulnerability_introduction_rate"
    ]
  },
  "samples": [
    {
      "id": "a2_cross_001",
      "input": {
        "repository": {
          "url": "https://github.com/sqlfluff/sqlfluff",
          "base_commit": "1000cf1beae75186cadf3a586c87e86e9f30ecb2"
        },
        "problem_statement": "L042 loop limit on fixes reached when CTE itself contains a subquery\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nWhile running `sqlfluff fix --dialect snowflake` on a sql file, I get\n```\n==== finding fixable violations ====\nWARNING Loop limit on fixes reached [10].\n==== no fixable linting violations found ====\nAll Finished ðŸ“œ ðŸŽ‰!\n[22 unfixable linting violations found]\n```\n\n```\nINSERT OVERWRITE INTO dwh.test_table\n\nWITH cte1 AS (\nSELECT *\nFROM (SELECT\n*,\nROW_NUMBER() OVER (PARTITION BY r ORDER BY updated_at DESC) AS latest\nFROM mongo.temp\nWHERE latest = 1\n))\n\nSELECT * FROM cte1 WHERE 1=1;\n```\n\nAll of the 22 violations are a mix of L002, L003 and L004.\n\n### Expected Behaviour\n\n`sqlfluff` should be able to fix the violations\n\n### Observed Behaviour\n\nEven if I try to fix the violations manually, it still shows the same error.\n\n### How to reproduce\n\nI will try to generate a sql file that will be able to reproduce the issue\n\n### Dialect\n\nSnowflake\n\n### Version\n\n1.1.0\n\n### Configuration\n\n```\n# https://docs.sqlfluff.com/en/stable/rules.html\n\n[sqlfluff]\nexclude_rules = L029, L031, L034\n\n[sqlfluff:indentation]\nindented_joins = true\nindented_using_on = true\n\n[sqlfluff:rules:L002]\ntab_space_size = 4\n\n[sqlfluff:rules:L003]\nhanging_indents = true\nindent_unit = tab\ntab_space_size = 4\n\n[sqlfluff:rules:L004]\nindent_unit = tab\ntab_space_size = 4\n\n[sqlfluff:rules:L010]\ncapitalisation_policy = upper\n\n[sqlfluff:rules:L011]\naliasing = explicit\n\n[sqlfluff:rules:L012]\naliasing = explicit\n\n[sqlfluff:rules:L014]\nextended_capitalisation_policy = lower\n\n[sqlfluff:rules:L016]\nignore_comment_clauses = true\nignore_comment_lines = true\nindent_unit = tab\ntab_space_size = 4\n\n[sqlfluff:rules:L019]\ncomma_style = trailing\n\n[sqlfluff:rules:L022]\ncomma_style = trailing\n\n[sqlfluff:rules:L028]\nsingle_table_references = unqualified\n\n[sqlfluff:rules:L030]\nextended_capitalisation_policy = upper\n\n[sqlfluff:rules:L040]\ncapitalisation_policy = upper\n\n[sqlfluff:rules:L042]\nforbid_subquery_in = both\n\n[sqlfluff:rules:L054]\ngroup_by_and_order_by_style = explicit\n\n[sqlfluff:rules:L063]\nextended_capitalisation_policy = upper\n\n[sqlfluff:rules:L066]\nmin_alias_length = 3\nmax_alias_length = 15\n\n[sqlfluff:templater:jinja:context]\nparams = {\"DB\": \"DEMO\"}\n```\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\nUnfortunately there is not much we can do without the SQL that produces this error (ideally a minimal reproducible example SQL) so will need to close this issue if we donâ€™t get that.\nI have updated the issue with a sample query. The query is very vague but it reproduces the error. Let me know if it helps.\nLooks like this simpler example also produces it:\n\n```sql\nWITH cte1 AS (\nSELECT a\nFROM (SELECT a)\n)\n\nSELECT a FROM cte1\n```\n\nThis only has one linting failure:\n\n```\n$ sqlfluff lint test.sql --dialect snowflake\n== [test.sql] FAIL\nL: 3 | P: 7 | L042 | from_expression_element clauses should not contain\n| subqueries. Use CTEs instead\nAll Finished ðŸ“œ ðŸŽ‰!\n```\n\nSo basically L042 gets in a recursive loop when trying to fix CTEs that also break L042.\n\nFor now you can manually fix that (or exclude L042 for this query) to prevent the error.\nAnother good test query:\n```\nWITH cte1 AS (\nSELECT *\nFROM (SELECT * FROM mongo.temp)\n)\n\nSELECT * FROM cte1\n```\nPR #3697 avoids the looping behavior. Lint issues are still flagged, but the rule does not attempt to fix it _if_ it would cause a loop. We should still try and figure out why this is happening, so the rule can actually autofix the code, but that's lower priority (and probably a separate PR)."
      },
      "expected_output": {
        "patch": "diff --git a/src/sqlfluff/core/parser/segments/base.py b/src/sqlfluff/core/parser/segments/base.py\n--- a/src/sqlfluff/core/parser/segments/base.py\n+++ b/src/sqlfluff/core/parser/segments/base.py\n@@ -1749,6 +1749,11 @@ def add(self, value): # MutableSet\n \"\"\"Add an element.\"\"\"\n self.map[self.key(value)] = value\n \n+ def update(self, value):\n+ \"\"\"Add elements in 'value'.\"\"\"\n+ for v in value:\n+ self.add(v)\n+\n def discard(self, value): # MutableSet\n \"\"\"Remove an element. Do not raise an exception if absent.\"\"\"\n self.map.pop(self.key(value), None) # pragma: no cover\ndiff --git a/src/sqlfluff/rules/L028.py b/src/sqlfluff/rules/L028.py\n--- a/src/sqlfluff/rules/L028.py\n+++ b/src/sqlfluff/rules/L028.py\n@@ -3,8 +3,9 @@\n from typing import Iterator, List, Optional, Set\n \n from sqlfluff.core.dialects.common import AliasInfo, ColumnAliasInfo\n-from sqlfluff.core.parser.segments.base import BaseSegment\n+from sqlfluff.core.parser.segments.base import BaseSegment, IdentitySet\n from sqlfluff.core.parser.segments.raw import SymbolSegment\n+from sqlfluff.utils.analysis.select import SelectStatementColumnsAndTables\n from sqlfluff.utils.analysis.select_crawler import Query, SelectCrawler\n from sqlfluff.core.rules import (\n BaseRule,\n@@ -99,12 +100,16 @@ def _eval(self, context: RuleContext) -> EvalResultType:\n \n if not FunctionalContext(context).parent_stack.any(sp.is_type(*_START_TYPES)):\n crawler = SelectCrawler(context.segment, context.dialect)\n+ visited: IdentitySet = IdentitySet()\n if crawler.query_tree:\n # Recursively visit and check each query in the tree.\n- return list(self._visit_queries(crawler.query_tree))\n+ return list(self._visit_queries(crawler.query_tree, visited))\n return None\n \n- def _visit_queries(self, query: Query) -> Iterator[LintResult]:\n+ def _visit_queries(\n+ self, query: Query, visited: IdentitySet\n+ ) -> Iterator[LintResult]:\n+ select_info: Optional[SelectStatementColumnsAndTables] = None\n if query.selectables:\n select_info = query.selectables[0].select_info\n # How many table names are visible from here? If more than one then do\n@@ -138,8 +143,24 @@ def _visit_queries(self, query: Query) -> Iterator[LintResult]:\n self._fix_inconsistent_to,\n fixable,\n )\n- for child in query.children:\n- yield from self._visit_queries(child)\n+ children = list(query.children)\n+ # 'query.children' includes CTEs and \"main\" queries, but not queries in\n+ # the \"FROM\" list. We want to visit those as well.\n+ if select_info:\n+ for a in select_info.table_aliases:\n+ for q in SelectCrawler.get(query, a.from_expression_element):\n+ if not isinstance(q, Query):\n+ continue\n+ # Check for previously visited selectables to avoid possible\n+ # infinite recursion, e.g.:\n+ # WITH test1 AS (SELECT i + 1, j + 1 FROM test1)\n+ # SELECT * FROM test1;\n+ if any(s.selectable in visited for s in q.selectables):\n+ continue\n+ visited.update(s.selectable for s in q.selectables)\n+ children.append(q)\n+ for child in children:\n+ yield from self._visit_queries(child, visited)\n \n \n def _check_references(\ndiff --git a/src/sqlfluff/rules/L042.py b/src/sqlfluff/rules/L042.py\n--- a/src/sqlfluff/rules/L042.py\n+++ b/src/sqlfluff/rules/L042.py\n@@ -2,7 +2,7 @@\n import copy\n from functools import partial\n from typing import (\n- Generator,\n+ Iterator,\n List,\n NamedTuple,\n Optional,\n@@ -12,7 +12,9 @@\n TypeVar,\n cast,\n )\n+\n from sqlfluff.core.dialects.base import Dialect\n+from sqlfluff.core.dialects.common import AliasInfo\n from sqlfluff.core.parser.segments.base import BaseSegment\n from sqlfluff.core.parser.segments.raw import (\n CodeSegment,\n@@ -21,8 +23,15 @@\n SymbolSegment,\n WhitespaceSegment,\n )\n-from sqlfluff.core.rules import BaseRule, LintFix, LintResult, RuleContext\n+from sqlfluff.core.rules import (\n+ BaseRule,\n+ EvalResultType,\n+ LintFix,\n+ LintResult,\n+ RuleContext,\n+)\n from sqlfluff.utils.analysis.select import get_select_statement_info\n+from sqlfluff.utils.analysis.select_crawler import Query, Selectable, SelectCrawler\n from sqlfluff.core.rules.crawlers import SegmentSeekerCrawler\n from sqlfluff.core.rules.doc_decorators import (\n document_configuration,\n@@ -51,10 +60,11 @@\n \n \n class _NestedSubQuerySummary(NamedTuple):\n- parent_clause_type: str\n- parent_select_segments: Segments\n- clause_segments: Segments\n- subquery: BaseSegment\n+ query: Query\n+ selectable: Selectable\n+ table_alias: AliasInfo\n+ sc: SelectCrawler\n+ select_source_names: Set[str]\n \n \n @document_groups\n@@ -107,137 +117,164 @@ class Rule_L042(BaseRule):\n \"both\": [\"join_clause\", \"from_expression_element\"],\n }\n \n- def _eval(self, context: RuleContext) -> Optional[List[LintResult]]:\n+ def _eval(self, context: RuleContext) -> EvalResultType:\n \"\"\"Join/From clauses should not contain subqueries. Use CTEs instead.\"\"\"\n self.forbid_subquery_in: str\n- parent_types = self._config_mapping[self.forbid_subquery_in]\n- segment = FunctionalContext(context).segment\n- parent_stack = FunctionalContext(context).parent_stack\n+ functional_context = FunctionalContext(context)\n+ segment = functional_context.segment\n+ parent_stack = functional_context.parent_stack\n+ is_select = segment.all(is_type(*_SELECT_TYPES))\n is_select_child = parent_stack.any(is_type(*_SELECT_TYPES))\n- if is_select_child:\n+ if not is_select or is_select_child:\n # Nothing to do.\n return None\n \n- # Gather all possible offending Elements in one crawl\n- nested_subqueries: List[_NestedSubQuerySummary] = []\n- selects = segment.recursive_crawl(*_SELECT_TYPES, recurse_into=True)\n- for select in selects.iterate_segments():\n- for res in _find_nested_subqueries(select, context.dialect):\n- if res.parent_clause_type not in parent_types:\n- continue\n- nested_subqueries.append(res)\n+ crawler = SelectCrawler(context.segment, context.dialect)\n+ assert crawler.query_tree\n+\n+ # generate an instance which will track and shape our output CTE\n+ ctes = _CTEBuilder()\n+ # Init the output/final select &\n+ # populate existing CTEs\n+ for cte in crawler.query_tree.ctes.values():\n+ ctes.insert_cte(cte.cte_definition_segment) # type: ignore\n+\n+ is_with = segment.all(is_type(\"with_compound_statement\"))\n+ # TODO: consider if we can fix recursive CTEs\n+ is_recursive = is_with and len(segment.children(is_keyword(\"recursive\"))) > 0\n+ case_preference = _get_case_preference(segment)\n+ output_select = segment\n+ if is_with:\n+ output_select = segment.children(\n+ is_type(\n+ \"set_expression\",\n+ \"select_statement\",\n+ )\n+ )\n \n- if not nested_subqueries:\n- return None\n # If there are offending elements calculate fixes\n- return _calculate_fixes(\n+ clone_map = SegmentCloneMap(segment[0])\n+ result = self._lint_query(\n dialect=context.dialect,\n- root_select=segment,\n- nested_subqueries=nested_subqueries,\n- parent_stack=parent_stack,\n+ query=crawler.query_tree,\n+ ctes=ctes,\n+ case_preference=case_preference,\n+ clone_map=clone_map,\n )\n \n- \n-def _calculate_fixes(\n- dialect: Dialect,\n- root_select: Segments,\n- nested_subqueries: List[_NestedSubQuerySummary],\n- parent_stack: Segments,\n-) -> List[LintResult]:\n- \"\"\"Given the Root select and the offending subqueries calculate fixes.\"\"\"\n- is_with = root_select.all(is_type(\"with_compound_statement\"))\n- # TODO: consider if we can fix recursive CTEs\n- is_recursive = is_with and len(root_select.children(is_keyword(\"recursive\"))) > 0\n- case_preference = _get_case_preference(root_select)\n- # generate an instance which will track and shape our output CTE\n- ctes = _CTEBuilder()\n- # Init the output/final select &\n- # populate existing CTEs\n- for cte in root_select.children(is_type(\"common_table_expression\")):\n- assert isinstance(cte, CTEDefinitionSegment), \"TypeGuard\"\n- ctes.insert_cte(cte)\n-\n- output_select = root_select\n- if is_with:\n- output_select = root_select.children(\n- is_type(\n- \"set_expression\",\n- \"select_statement\",\n+ if result:\n+ lint_result, from_expression, alias_name, subquery_parent = result\n+ assert any(\n+ from_expression is seg for seg in subquery_parent.recursive_crawl_all()\n )\n- )\n+ this_seg_clone = clone_map[from_expression]\n+ new_table_ref = _create_table_ref(alias_name, context.dialect)\n+ this_seg_clone.segments = [new_table_ref]\n+ ctes.replace_with_clone(subquery_parent, clone_map)\n+\n+ # Issue 3617: In T-SQL (and possibly other dialects) the automated fix\n+ # leaves parentheses in a location that causes a syntax error. This is an\n+ # unusual corner case. For simplicity, we still generate the lint warning\n+ # but don't try to generate a fix. Someone could look at this later (a\n+ # correct fix would involve removing the parentheses.)\n+ bracketed_ctas = [seg.type for seg in parent_stack[-2:]] == [\n+ \"create_table_statement\",\n+ \"bracketed\",\n+ ]\n+ if bracketed_ctas or ctes.has_duplicate_aliases() or is_recursive:\n+ # If we have duplicate CTE names just don't fix anything\n+ # Return the lint warnings anyway\n+ return lint_result\n+\n+ # Compute fix.\n+ edit = [\n+ ctes.compose_select(\n+ clone_map[output_select[0]],\n+ case_preference=case_preference,\n+ ),\n+ ]\n+ lint_result.fixes = [\n+ LintFix.replace(\n+ segment[0],\n+ edit_segments=edit,\n+ )\n+ ]\n+ return lint_result\n+ return None\n \n- lint_results: List[LintResult] = []\n- clone_map = SegmentCloneMap(root_select[0])\n- is_new_name = False\n- new_table_ref = None\n- for parent_type, _, this_seg, subquery in nested_subqueries:\n- alias_name, is_new_name = ctes.create_cte_alias(\n- this_seg.children(is_type(\"alias_expression\"))\n- )\n- new_cte = _create_cte_seg(\n- alias_name=alias_name,\n- subquery=clone_map[subquery],\n- case_preference=case_preference,\n- dialect=dialect,\n- )\n- ctes.insert_cte(new_cte)\n- this_seg_clone = clone_map[this_seg[0]]\n- assert this_seg_clone.pos_marker, \"TypeGuard\"\n- new_table_ref = _create_table_ref(alias_name, dialect)\n- this_seg_clone.segments = (new_table_ref,)\n- anchor = subquery\n- # Grab the first keyword or symbol in the subquery to use as the\n- # anchor. This makes the lint warning less likely to be filtered out\n- # if a bit of the subquery happens to be templated.\n- for seg in subquery.recursive_crawl(\"keyword\", \"symbol\"):\n- anchor = seg\n- break\n- res = LintResult(\n- anchor=anchor,\n- description=f\"{parent_type} clauses should not contain \"\n- \"subqueries. Use CTEs instead\",\n- fixes=[],\n- )\n- lint_results.append(res)\n-\n- # Issue 3617: In T-SQL (and possibly other dialects) the automated fix\n- # leaves parentheses in a location that causes a syntax error. This is an\n- # unusual corner case. For simplicity, we still generate the lint warning\n- # but don't try to generate a fix. Someone could look at this later (a\n- # correct fix would involve removing the parentheses.)\n- bracketed_ctas = [seg.type for seg in parent_stack[-2:]] == [\n- \"create_table_statement\",\n- \"bracketed\",\n- ]\n- if bracketed_ctas or ctes.has_duplicate_aliases() or is_recursive:\n- # If we have duplicate CTE names just don't fix anything\n- # Return the lint warnings anyway\n- return lint_results\n-\n- # Add fixes to the last result only\n- edit = [\n- ctes.compose_select(\n- clone_map[output_select[0]],\n- case_preference=case_preference,\n- ),\n- ]\n- lint_results[-1].fixes = [\n- LintFix.replace(\n- root_select[0],\n- edit_segments=edit,\n- )\n- ]\n- if is_new_name:\n- assert lint_results[0].fixes[0].edit\n- assert new_table_ref\n- # If we're creating a new CTE name but the CTE name does not appear in\n- # the fix, discard the lint error. This prevents the rule from looping,\n- # i.e. making the same fix repeatedly.\n- if not any(\n- seg.uuid == new_table_ref.uuid for seg in edit[0].recursive_crawl_all()\n- ):\n- lint_results[-1].fixes = []\n- return lint_results\n+ def _nested_subqueries(\n+ self, query: Query, dialect: Dialect\n+ ) -> Iterator[_NestedSubQuerySummary]:\n+ parent_types = self._config_mapping[self.forbid_subquery_in]\n+ for q in [query] + list(query.ctes.values()):\n+ for selectable in q.selectables:\n+ if not selectable.select_info:\n+ continue # pragma: no cover\n+ select_source_names = set()\n+ for a in selectable.select_info.table_aliases:\n+ # For each table in FROM, return table name and any alias.\n+ if a.ref_str:\n+ select_source_names.add(a.ref_str)\n+ if a.object_reference:\n+ select_source_names.add(a.object_reference.raw)\n+ for table_alias in selectable.select_info.table_aliases:\n+ sc = SelectCrawler(table_alias.from_expression_element, dialect)\n+ if sc.query_tree:\n+ path_to = selectable.selectable.path_to(\n+ table_alias.from_expression_element\n+ )\n+ if not any(seg.is_type(*parent_types) for seg in path_to):\n+ continue\n+ if _is_correlated_subquery(\n+ Segments(sc.query_tree.selectables[0].selectable),\n+ select_source_names,\n+ dialect,\n+ ):\n+ continue\n+ yield _NestedSubQuerySummary(\n+ q, selectable, table_alias, sc, select_source_names\n+ )\n+\n+ def _lint_query(\n+ self,\n+ dialect: Dialect,\n+ query: Query,\n+ ctes: \"_CTEBuilder\",\n+ case_preference,\n+ clone_map,\n+ ) -> Optional[Tuple[LintResult, BaseSegment, str, BaseSegment]]:\n+ \"\"\"Given the root query, compute lint warnings.\"\"\"\n+ nsq: _NestedSubQuerySummary\n+ for nsq in self._nested_subqueries(query, dialect):\n+ alias_name, is_new_name = ctes.create_cte_alias(nsq.table_alias)\n+ anchor = nsq.table_alias.from_expression_element.segments[0]\n+ new_cte = _create_cte_seg(\n+ alias_name=alias_name,\n+ subquery=clone_map[anchor],\n+ case_preference=case_preference,\n+ dialect=dialect,\n+ )\n+ ctes.insert_cte(new_cte)\n+\n+ # Grab the first keyword or symbol in the subquery to\n+ # use as the anchor. This makes the lint warning less\n+ # likely to be filtered out if a bit of the subquery\n+ # happens to be templated.\n+ anchor = next(anchor.recursive_crawl(\"keyword\", \"symbol\"))\n+ res = LintResult(\n+ anchor=anchor,\n+ description=f\"{nsq.query.selectables[0].selectable.type} clauses \"\n+ \"should not contain subqueries. Use CTEs instead\",\n+ fixes=[],\n+ )\n+ if len(nsq.query.selectables) == 1:\n+ return (\n+ res,\n+ nsq.table_alias.from_expression_element,\n+ alias_name,\n+ nsq.query.selectables[0].selectable,\n+ )\n+ return None\n \n \n def _get_first_select_statement_descendant(\n@@ -252,27 +289,6 @@ def _get_first_select_statement_descendant(\n return None # pragma: no cover\n \n \n-def _get_sources_from_select(segment: BaseSegment, dialect: Dialect) -> Set[str]:\n- \"\"\"Given segment, return set of table or alias names it queries from.\"\"\"\n- result = set()\n- select = None\n- if segment.is_type(\"select_statement\"):\n- select = segment\n- elif segment.is_type(\"with_compound_statement\"):\n- # For WITH statement, process the main query underneath.\n- select = _get_first_select_statement_descendant(segment)\n- if select and select.is_type(\"select_statement\"):\n- select_info = get_select_statement_info(select, dialect)\n- if select_info:\n- for a in select_info.table_aliases:\n- # For each table in FROM, return table name and any alias.\n- if a.ref_str:\n- result.add(a.ref_str)\n- if a.object_reference:\n- result.add(a.object_reference.raw)\n- return result\n-\n-\n def _is_correlated_subquery(\n nested_select: Segments, select_source_names: Set[str], dialect: Dialect\n ):\n@@ -280,8 +296,6 @@ def _is_correlated_subquery(\n \n https://en.wikipedia.org/wiki/Correlated_subquery\n \"\"\"\n- if not nested_select:\n- return False # pragma: no cover\n select_statement = _get_first_select_statement_descendant(nested_select[0])\n if not select_statement:\n return False # pragma: no cover\n@@ -298,51 +312,6 @@ def _is_correlated_subquery(\n return False\n \n \n-def _find_nested_subqueries(\n- select: Segments,\n- dialect: Dialect,\n-) -> Generator[_NestedSubQuerySummary, None, None]:\n- \"\"\"Find possible offending elements and return enough to fix them.\"\"\"\n- select_types = [\n- \"with_compound_statement\",\n- \"set_expression\",\n- \"select_statement\",\n- ]\n- from_clause = select.children().first(is_type(\"from_clause\")).children()\n- offending_types = [\"join_clause\", \"from_expression_element\"]\n- select_source_names = _get_sources_from_select(select[0], dialect)\n-\n- # Match any of the types we care about\n- for this_seg in from_clause.children(is_type(*offending_types)).iterate_segments():\n- parent_type = this_seg[0].get_type()\n- # Ensure we are at the right depth (from_expression_element)\n- if not this_seg.all(is_type(\"from_expression_element\")):\n- this_seg = this_seg.children(\n- is_type(\"from_expression_element\"),\n- )\n-\n- table_expression_el = this_seg.children(\n- is_type(\"table_expression\"),\n- )\n-\n- # Is it bracketed? If so, lint that instead.\n- bracketed_expression = table_expression_el.children(\n- is_type(\"bracketed\"),\n- )\n- nested_select = bracketed_expression or table_expression_el\n- # If we find a child with a \"problem\" type, raise an issue.\n- # If not, we're fine.\n- seg = nested_select.children(is_type(*select_types))\n- if not seg:\n- # If there is no match there is no error\n- continue\n- # Type, parent_select, parent_sequence\n- if not _is_correlated_subquery(nested_select, select_source_names, dialect):\n- yield _NestedSubQuerySummary(\n- parent_type, select, this_seg, table_expression_el[0]\n- )\n-\n-\n class _CTEBuilder:\n \"\"\"Gather CTE parts, maintain order and track naming/aliasing.\"\"\"\n \n@@ -369,7 +338,9 @@ def has_duplicate_aliases(self) -> bool:\n def insert_cte(self, cte: CTEDefinitionSegment):\n \"\"\"Add a new CTE to the list as late as possible but before all its parents.\"\"\"\n # This should still have the position markers of its true position\n- inbound_subquery = Segments(cte).children().last()\n+ inbound_subquery = (\n+ Segments(cte).children().last(lambda seg: bool(seg.pos_marker))\n+ )\n insert_position = next(\n (\n i\n@@ -381,14 +352,11 @@ def insert_cte(self, cte: CTEDefinitionSegment):\n \n self.ctes.insert(insert_position, cte)\n \n- def create_cte_alias(\n- self, alias_segment: Optional[Segments] = None\n- ) -> Tuple[str, bool]:\n+ def create_cte_alias(self, alias: Optional[AliasInfo]) -> Tuple[str, bool]:\n \"\"\"Find or create the name for the next CTE.\"\"\"\n- if alias_segment:\n+ if alias and alias.aliased and alias.ref_str:\n # If we know the name use it\n- name = alias_segment.children().last()[0].raw\n- return name, False\n+ return alias.ref_str, False\n \n self.name_idx = self.name_idx + 1\n name = f\"prep_{self.name_idx}\"\n@@ -398,7 +366,7 @@ def create_cte_alias(\n return name, True\n \n def get_cte_segments(self) -> List[BaseSegment]:\n- \"\"\"Return a valid list of CTES with required padding Segements.\"\"\"\n+ \"\"\"Return a valid list of CTES with required padding segments.\"\"\"\n cte_segments: List[BaseSegment] = []\n for cte in self.ctes:\n cte_segments = cte_segments + [\n@@ -439,16 +407,24 @@ def compose_select(self, output_select: BaseSegment, case_preference: str):\n )\n return new_select\n \n+ def replace_with_clone(self, segment, clone_map):\n+ for idx, cte in enumerate(self.ctes):\n+ if any(segment is seg for seg in cte.recursive_crawl_all()):\n+ self.ctes[idx] = clone_map[self.ctes[idx]]\n+ return\n+\n \n def _is_child(maybe_parent: Segments, maybe_child: Segments) -> bool:\n \"\"\"Is the child actually between the start and end markers of the parent.\"\"\"\n- assert len(maybe_child) == 1, \"Cannot assess Childness of multiple Segments\"\n- assert len(maybe_parent) == 1, \"Cannot assess Childness of multiple Parents\"\n+ assert (\n+ len(maybe_child) == 1\n+ ), \"Cannot assess child relationship of multiple segments\"\n+ assert (\n+ len(maybe_parent) == 1\n+ ), \"Cannot assess child relationship of multiple parents\"\n child_markers = maybe_child[0].pos_marker\n parent_pos = maybe_parent[0].pos_marker\n- if not parent_pos or not child_markers:\n- return False # pragma: no cover\n-\n+ assert parent_pos and child_markers\n if child_markers < parent_pos.start_point_marker():\n return False # pragma: no cover\n \ndiff --git a/src/sqlfluff/utils/analysis/select_crawler.py b/src/sqlfluff/utils/analysis/select_crawler.py\n--- a/src/sqlfluff/utils/analysis/select_crawler.py\n+++ b/src/sqlfluff/utils/analysis/select_crawler.py\n@@ -33,8 +33,13 @@ class Selectable:\n \"\"\"A \"SELECT\" query segment.\"\"\"\n \n selectable: BaseSegment\n+ parent: Optional[BaseSegment]\n dialect: Dialect\n \n+ def as_str(self) -> str:\n+ \"\"\"String representation for logging/testing.\"\"\"\n+ return self.selectable.raw\n+\n @cached_property\n def select_info(self):\n \"\"\"Returns SelectStatementColumnsAndTables on the SELECT.\"\"\"\n@@ -112,7 +117,7 @@ def find_alias(self, table: str) -> Optional[AliasInfo]:\n \"\"\"Find corresponding table_aliases entry (if any) matching \"table\".\"\"\"\n alias_info = [\n t\n- for t in self.select_info.table_aliases\n+ for t in (self.select_info.table_aliases if self.select_info else [])\n if t.aliased and t.ref_str == table\n ]\n assert len(alias_info) <= 1\n@@ -131,8 +136,24 @@ class Query:\n parent: Optional[\"Query\"] = field(default=None)\n # Children (could be CTE, subselect, or other).\n children: List[\"Query\"] = field(default_factory=list)\n+ cte_definition_segment: Optional[BaseSegment] = field(default=None)\n cte_name_segment: Optional[BaseSegment] = field(default=None)\n \n+ def as_json(self) -> Dict:\n+ \"\"\"JSON representation for logging/testing.\"\"\"\n+ result = {}\n+ if self.query_type != QueryType.Simple:\n+ result[\"query_type\"] = self.query_type.name\n+ if self.selectables:\n+ result[\"selectables\"] = [\n+ s.as_str() for s in self.selectables\n+ ] # type: ignore\n+ if self.ctes:\n+ result[\"ctes\"] = {\n+ k: v.as_json() for k, v in self.ctes.items()\n+ } # type: ignore\n+ return result\n+\n def lookup_cte(self, name: str, pop: bool = True) -> Optional[\"Query\"]:\n \"\"\"Look up a CTE by name, in the current or any parent scope.\"\"\"\n cte = self.ctes.get(name.upper())\n@@ -146,7 +167,7 @@ def lookup_cte(self, name: str, pop: bool = True) -> Optional[\"Query\"]:\n return None\n \n def crawl_sources(\n- self, segment: BaseSegment, recurse_into=True, pop=False\n+ self, segment: BaseSegment, recurse_into=True, pop=False, lookup_cte=True\n ) -> Generator[Union[str, \"Query\"], None, None]:\n \"\"\"Find SELECTs, table refs, or value table function calls in segment.\n \n@@ -154,20 +175,26 @@ def crawl_sources(\n references or function call strings, yield those.\n \"\"\"\n found_nested_select = False\n- for seg in segment.recursive_crawl(\n+ types = [\n \"table_reference\",\n \"set_expression\",\n \"select_statement\",\n \"values_clause\",\n- recurse_into=recurse_into,\n+ ]\n+ for event, path in SelectCrawler.visit_segments(\n+ segment, recurse_into=recurse_into\n ):\n+ seg = path[-1]\n+ if event == \"end\" or not seg.is_type(*types):\n+ continue\n+\n if seg is segment:\n # If the starting segment itself matches the list of types we're\n # searching for, recursive_crawl() will return it. Skip that.\n continue\n \n if seg.is_type(\"table_reference\"):\n- if not seg.is_qualified():\n+ if not seg.is_qualified() and lookup_cte:\n cte = self.lookup_cte(seg.raw, pop=pop)\n if cte:\n # It's a CTE.\n@@ -179,7 +206,15 @@ def crawl_sources(\n \"set_expression\", \"select_statement\", \"values_clause\"\n )\n found_nested_select = True\n- crawler = SelectCrawler(seg, self.dialect, parent=self)\n+ seg_ = Segments(*path[1:]).first(\n+ sp.is_type(\n+ \"from_expression_element\",\n+ \"set_expression\",\n+ \"select_statement\",\n+ \"values_clause\",\n+ )\n+ )[0]\n+ crawler = SelectCrawler(seg_, self.dialect, parent=self)\n # We know this will pass because we specified parent=self above.\n assert crawler.query_tree\n yield crawler.query_tree\n@@ -234,9 +269,10 @@ def finish_segment():\n except ValueError:\n pass\n \n- # Stores the last CTE name we saw, so we can associate it with the\n- # corresponding Query.\n- cte_name_segment: Optional[BaseSegment] = None\n+ # Stacks for CTE definition & names we've seen but haven't consumed yet,\n+ # so we can associate with the corresponding Query.\n+ cte_definition_segment_stack: List[BaseSegment] = []\n+ cte_name_segment_stack: List[BaseSegment] = []\n \n # Visit segment and all its children\n for event, path in SelectCrawler.visit_segments(segment):\n@@ -263,9 +299,17 @@ def finish_segment():\n # added to this Query later.\n query = self.query_class(QueryType.Simple, dialect)\n append_query(query)\n- else:\n+ # Ignore segments under a from_expression_element.\n+ # Those will be nested queries, and we're only\n+ # interested in CTEs and \"main\" queries, i.e.\n+ # standalones or those following a block of CTEs.\n+ elif not any(\n+ seg.is_type(\"from_expression_element\") for seg in path[1:]\n+ ):\n # It's a select_statement or values_clause.\n- selectable = Selectable(path[-1], dialect)\n+ selectable = Selectable(\n+ path[-1], path[-2] if len(path) >= 2 else None, dialect\n+ )\n # Determine if this is part of a set_expression.\n if len(path) >= 2 and path[-2].is_type(\"set_expression\"):\n # It's part of a set_expression. Append to the\n@@ -280,27 +324,37 @@ def finish_segment():\n append_query(query)\n else:\n # We're processing a \"with\" statement.\n- if cte_name_segment:\n+ if cte_name_segment_stack:\n # If we have a CTE name, this is the Query for that\n # name.\n query = self.query_class(\n QueryType.Simple,\n dialect,\n- cte_name_segment=cte_name_segment,\n+ cte_definition_segment=cte_definition_segment_stack[-1],\n+ cte_name_segment=cte_name_segment_stack[-1],\n )\n if path[-1].is_type(\n \"select_statement\", \"values_clause\", \"update_statement\"\n ):\n # Add to the Query object we just created.\n- query.selectables.append(Selectable(path[-1], dialect))\n+ query.selectables.append(\n+ Selectable(\n+ path[-1],\n+ path[-2] if len(path) >= 2 else None,\n+ dialect,\n+ )\n+ )\n else:\n # Processing a set_expression. Nothing\n # additional to do here; we'll add selectables\n # to the Query later when we encounter those\n # child segments.\n pass\n- query_stack[-1].ctes[cte_name_segment.raw_upper] = query\n- cte_name_segment = None\n+ query_stack[-1].ctes[\n+ cte_name_segment_stack[-1].raw_upper\n+ ] = query\n+ cte_definition_segment_stack.pop()\n+ cte_name_segment_stack.pop()\n append_query(query)\n else:\n # There's no CTE name, so we're probably processing\n@@ -311,7 +365,8 @@ def finish_segment():\n # interested in CTEs and \"main\" queries, i.e.\n # standalones or those following a block of CTEs.\n if not any(\n- seg.is_type(\"from_expression_element\") for seg in path\n+ seg.is_type(\"from_expression_element\")\n+ for seg in path[1:]\n ):\n if path[-1].is_type(\n \"select_statement\", \"update_statement\"\n@@ -319,7 +374,11 @@ def finish_segment():\n # Processing a select_statement. Add it to the\n # Query object on top of the stack.\n query_stack[-1].selectables.append(\n- Selectable(path[-1], dialect)\n+ Selectable(\n+ path[-1],\n+ path[-2] if len(path) >= 2 else None,\n+ dialect,\n+ )\n )\n else:\n # Processing a set_expression. Nothing\n@@ -328,13 +387,19 @@ def finish_segment():\n elif path[-1].is_type(\"with_compound_statement\"):\n # Beginning a \"with\" statement, i.e. a block of CTEs.\n query = self.query_class(QueryType.WithCompound, dialect)\n- if cte_name_segment:\n- query_stack[-1].ctes[cte_name_segment.raw_upper] = query\n- cte_name_segment = None\n+ if cte_name_segment_stack:\n+ query_stack[-1].ctes[\n+ cte_name_segment_stack[-1].raw_upper\n+ ] = query\n+ query.cte_definition_segment = cte_definition_segment_stack[-1]\n+ cte_definition_segment_stack.pop()\n+ cte_name_segment_stack.pop()\n append_query(query)\n elif path[-1].is_type(\"common_table_expression\"):\n- # This is a \"<<cte name>> AS\". Grab the name for later.\n- cte_name_segment = path[-1].segments[0]\n+ # This is a \"<<cte name>> AS\". Save definition segment and\n+ # name for later.\n+ cte_definition_segment_stack.append(path[-1])\n+ cte_name_segment_stack.append(path[-1].segments[0])\n elif event == \"end\":\n finish_segment()\n \n@@ -355,13 +420,14 @@ def get(cls, query: Query, segment: BaseSegment) -> List[Union[str, \"Query\"]]:\n return list(query.crawl_sources(segment, True))\n \n @classmethod\n- def visit_segments(cls, seg, path=None):\n+ def visit_segments(cls, seg, path=None, recurse_into=True):\n \"\"\"Recursively visit all segments.\"\"\"\n if path is None:\n path = []\n path.append(seg)\n yield \"start\", path\n- for seg in seg.segments:\n- yield from cls.visit_segments(seg, path)\n+ if recurse_into:\n+ for seg in seg.segments:\n+ yield from cls.visit_segments(seg, path, recurse_into)\n yield \"end\", path\n path.pop()\ndiff --git a/test/fixtures/rules/std_rule_cases/L042.yml b/test/fixtures/rules/std_rule_cases/L042.yml\n--- a/test/fixtures/rules/std_rule_cases/L042.yml\n+++ b/test/fixtures/rules/std_rule_cases/L042.yml\n@@ -99,7 +99,7 @@ double_nested_fail:\n L042:\n forbid_subquery_in: both\n \n-double_nested_unfixable_cte_clash:\n+double_nested_fail_2:\n fail_str: |\n select\n a.x, a.y, b.z\n@@ -109,6 +109,20 @@ double_nested_unfixable_cte_clash:\n select x, z from p_cte\n ) as b\n ) as b on (a.x = b.x)\n+ fix_str: |\n+ with b as (\n+ select x, z from (\n+ select x, z from p_cte\n+ ) as b\n+ )\n+ select\n+ a.x, a.y, b.z\n+ from a\n+ join b on (a.x = b.x)\n+ violations_after_fix:\n+ - description: select_statement clauses should not contain subqueries. Use CTEs instead\n+ line_no: 2\n+ line_pos: 20\n configs:\n rules:\n L042:\n@@ -127,6 +141,23 @@ unfixable_cte_clash:\n select 1\n ) as b\n ) as c on (a.x = b.x)\n+ fix_str: |\n+ with \"b\" as (\n+ select x, z from p_cte\n+ ),\n+ c as (\n+ select x, z from (\n+ select 1\n+ ) as b\n+ )\n+ select\n+ a.x, a.y, b.z\n+ from a\n+ join c on (a.x = b.x)\n+ violations_after_fix:\n+ - description: select_statement clauses should not contain subqueries. Use CTEs instead\n+ line_no: 5\n+ line_pos: 20\n configs:\n rules:\n L042:\n@@ -458,10 +489,16 @@ issue_3572_correlated_subquery_3:\n issue_3598_avoid_looping_1:\n fail_str: |\n WITH cte1 AS (\n- SELECT a\n- FROM (SELECT a)\n+ SELECT a\n+ FROM (SELECT a)\n+ )\n+ SELECT a FROM cte1\n+ fix_str: |\n+ WITH prep_1 AS (SELECT a),\n+ cte1 AS (\n+ SELECT a\n+ FROM prep_1\n )\n-\n SELECT a FROM cte1\n configs:\n rules:\n@@ -474,8 +511,37 @@ issue_3598_avoid_looping_2:\n SELECT *\n FROM (SELECT * FROM mongo.temp)\n )\n-\n SELECT * FROM cte1\n+ fix_str: |\n+ WITH prep_1 AS (SELECT * FROM mongo.temp),\n+ cte1 AS (\n+ SELECT *\n+ FROM prep_1\n+ )\n+ SELECT * FROM cte1\n+ configs:\n+ rules:\n+ L042:\n+ forbid_subquery_in: both\n+\n+test_fail_subquery_in_cte:\n+ fail_str: |\n+ with b as (\n+ select x, z from (\n+ select x, z from p_cte\n+ )\n+ )\n+ select b.z\n+ from b\n+ fix_str: |\n+ with prep_1 as (\n+ select x, z from p_cte\n+ ),\n+ b as (\n+ select x, z from prep_1\n+ )\n+ select b.z\n+ from b\n configs:\n rules:\n L042:\ndiff --git a/test/utils/analysis/test_select_crawler.py b/test/utils/analysis/test_select_crawler.py\nnew file mode 100644\n--- /dev/null\n+++ b/test/utils/analysis/test_select_crawler.py\n@@ -0,0 +1,197 @@\n+\"\"\"Test the select_crawler module.\"\"\"\n+import pytest\n+\n+from sqlfluff.core.linter.linter import Linter\n+from sqlfluff.utils.analysis import select_crawler\n+\n+\n+@pytest.mark.parametrize(\n+ \"sql, expected_json\",\n+ [\n+ (\n+ # Test trivial query.\n+ \"select 1\",\n+ {\"selectables\": [\"select 1\"]},\n+ ),\n+ (\n+ # Test set expression.\n+ \"select 1 union select 2\",\n+ {\"selectables\": [\"select 1\", \"select 2\"]},\n+ ),\n+ (\n+ # Test multiple CTEs.\n+ \"with cte1 as (select 1 as x), cte2 as (select 2 as y) \"\n+ \"select * from cte1 join cte2 using (x)\",\n+ {\n+ \"ctes\": {\n+ \"CTE1\": {\"selectables\": [\"select 1 as x\"]},\n+ \"CTE2\": {\"selectables\": [\"select 2 as y\"]},\n+ },\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\"select * from cte1 join cte2 using (x)\"],\n+ },\n+ ),\n+ (\n+ # Nested CTEs (from L044 test suite)\n+ \"\"\"\n+ with a as (\n+ with b as (select 1 from c)\n+ select * from b\n+ )\n+ select * from a\n+ \"\"\",\n+ {\n+ \"ctes\": {\n+ \"A\": {\n+ \"ctes\": {\"B\": {\"selectables\": [\"select 1 from c\"]}},\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\"select * from b\"],\n+ }\n+ },\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\"select * from a\"],\n+ },\n+ ),\n+ (\n+ # Nested CTEs (from L044 test suite)\n+ \"\"\"\n+ with b as (select 1 from c)\n+ select * from (\n+ with a as (select * from b)\n+ select * from a\n+ )\n+ \"\"\",\n+ {\n+ \"ctes\": {\"B\": {\"selectables\": [\"select 1 from c\"]}},\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\n+ \"select * from (\\n\"\n+ \" with a as (select * from b)\\n\"\n+ \" select * from a\\n\"\n+ \" )\"\n+ ],\n+ },\n+ ),\n+ (\n+ # Test that subquery in \"from\" not included.\n+ \"select a.x from (select z from b)\",\n+ {\"selectables\": [\"select a.x from (select z from b)\"]},\n+ ),\n+ (\n+ # Test that subquery in \"from\" / \"join\" not included.\n+ \"select a.x from a join (select z from b) as b on (a.x = b.x)\",\n+ {\n+ \"selectables\": [\n+ \"select a.x from a join (select z from b) as b on (a.x = b.x)\"\n+ ]\n+ },\n+ ),\n+ (\n+ # In CTE main query, test that subquery in \"from\" not included.\n+ \"with prep as (select 1) select a.x from (select z from b)\",\n+ {\n+ \"ctes\": {\"PREP\": {\"selectables\": [\"select 1\"]}},\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\"select a.x from (select z from b)\"],\n+ },\n+ ),\n+ (\n+ # In CTE main query, test that subquery in \"from\" / \"join\" not included.\n+ \"with prep as (select 1) \"\n+ \"select a.x from a join (select z from b) as b on (a.x = b.x)\",\n+ {\n+ \"ctes\": {\"PREP\": {\"selectables\": [\"select 1\"]}},\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\n+ \"select a.x from a join (select z from b) as b on (a.x = \" \"b.x)\"\n+ ],\n+ },\n+ ),\n+ (\n+ \"\"\"with prep_1 as (\n+ with d as (\n+ select x, z from b\n+ )\n+ select * from d\n+)\n+select\n+ a.x, a.y, b.z\n+from a\n+join prep_1 using (x)\n+\"\"\",\n+ {\n+ \"ctes\": {\n+ \"PREP_1\": {\n+ \"ctes\": {\n+ \"D\": {\"selectables\": [\"select x, z from b\"]},\n+ },\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\"select * from d\"],\n+ }\n+ },\n+ \"query_type\": \"WithCompound\",\n+ \"selectables\": [\n+ \"select\\n a.x, a.y, b.z\\nfrom a\\njoin prep_1 using (x)\"\n+ ],\n+ },\n+ ),\n+ ],\n+)\n+def test_select_crawler_constructor(sql, expected_json):\n+ \"\"\"Test SelectCrawler when created using constructor.\"\"\"\n+ linter = Linter(dialect=\"ansi\")\n+ parsed = linter.parse_string(sql)\n+ segments = list(\n+ parsed.tree.recursive_crawl(\n+ \"with_compound_statement\",\n+ \"set_expression\",\n+ \"select_statement\",\n+ )\n+ )\n+ segment = segments[0]\n+ crawler = select_crawler.SelectCrawler(segment, linter.dialect)\n+ assert all(\n+ cte.cte_definition_segment is not None\n+ for cte in crawler.query_tree.ctes.values()\n+ )\n+ json_query_tree = crawler.query_tree.as_json()\n+ assert expected_json == json_query_tree\n+\n+\n+def test_select_crawler_nested():\n+ \"\"\"Test invoking with an outer from_expression_segment.\"\"\"\n+ sql = \"\"\"\n+select\n+ a.x, a.y, b.z\n+from a\n+join (\n+ with d as (\n+ select x, z from b\n+ )\n+ select * from d\n+) using (x)\n+ \"\"\"\n+ linter = Linter(dialect=\"ansi\")\n+ parsed = linter.parse_string(sql)\n+ segments = list(\n+ parsed.tree.recursive_crawl(\n+ \"with_compound_statement\",\n+ \"set_expression\",\n+ \"select_statement\",\n+ )\n+ )\n+ segment = segments[0]\n+ crawler = select_crawler.SelectCrawler(segment, linter.dialect)\n+ sc = select_crawler.SelectCrawler(\n+ crawler.query_tree.selectables[0]\n+ .select_info.table_aliases[1]\n+ .from_expression_element,\n+ linter.dialect,\n+ )\n+ assert sc.query_tree.as_json() == {\n+ \"selectables\": [\n+ \"select * from d\",\n+ ],\n+ \"ctes\": {\"D\": {\"selectables\": [\"select x, z from b\"]}},\n+ \"query_type\": \"WithCompound\",\n+ }",
        "modified_files": [
          "src/sqlfluff/core/parser/segments/base.py",
          "src/sqlfluff/rules/L028.py",
          "src/sqlfluff/rules/L042.py",
          "src/sqlfluff/utils/analysis/select_crawler.py",
          "test/fixtures/rules/std_rule_cases/L042.yml",
          "test/utils/analysis/test_select_crawler.py"
        ]
      },
      "environment_setup": {
        "install_command": "pip install -e .",
        "python_version": "3.9"
      },
      "evaluation": {
        "test_cases": {
          "fail_to_pass": [
            "test/utils/analysis/test_select_crawler.py::test_select_crawler_constructor[select",
            "test/utils/analysis/test_select_crawler.py::test_select_crawler_constructor[with",
            "test/utils/analysis/test_select_crawler.py::test_select_crawler_constructor[\\n",
            "test/utils/analysis/test_select_crawler.py::test_select_crawler_nested"
          ],
          "pass_to_pass": []
        },
        "new_vulnerability_check": {
          "scan_fixed_code": true,
          "check_for_new_issues": [
            "improper_input_validation",
            "sql_injection",
            "cross_site_scripting",
            "os_command_injection",
            "path_traversal",
            "deserialization_of_untrusted_data",
            "hardcoded_cryptographic_key",
            "plaintext_password_storage",
            "improper_authentication",
            "ssrf"
          ],
          "regression_tests": true
        },
        "comparison_method": "test_suite_execution"
      },
      "metadata": {
        "source": "SWE-bench"
      }
    }
  ]
}
